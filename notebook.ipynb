{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eaabe7791de8e2",
   "metadata": {},
   "source": [
    "## Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0866b873e18ef1",
   "metadata": {},
   "source": [
    "Dask - это библиотека для параллельных вычислений и масштабирования. Допустим, что Numpy не справляется с объемом данных, который нам нужно будет обработать. В таком случае естественной альтернативой как раз станет Dask. Dask предоставляет возможность работать с данными, которые превышают объем оперативной памяти, и эффективно использовать ресурсы как на локальной машине, так и на кластере. Библиотека позволяет масштабировать код Python с минимальными изменениями."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0472af2d568ca8d",
   "metadata": {},
   "source": [
    "## Полезные ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29291f71cc75d8d2",
   "metadata": {},
   "source": [
    "[Тык](https://docs.dask.org/en/stable/)\n",
    "\n",
    "[Тык](https://tutorial.dask.org/00_overview.html)\n",
    "\n",
    "[Тык](https://habr.com/ru/companies/otus/articles/759552/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38d1de40e22ccbd",
   "metadata": {},
   "source": [
    "## Установка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1454e34d3ca316",
   "metadata": {},
   "source": [
    "Здесь все стандартно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T09:18:47.576563Z",
     "start_time": "2024-12-10T09:18:46.714320Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dask[complete] in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2024.12.0)\n",
      "Requirement already satisfied: click>=8.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (3.1.0)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (24.2)\n",
      "Requirement already satisfied: partd>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (6.0.2)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (1.0.0)\n",
      "Requirement already satisfied: pyarrow>=14.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (18.1.0)\n",
      "Requirement already satisfied: lz4>=4.3.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (4.3.3)\n",
      "Requirement already satisfied: locket in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from partd>=1.4.0->dask[complete]) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.24 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (2.1.2)\n",
      "Requirement already satisfied: pandas>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (2.2.3)\n",
      "Requirement already satisfied: dask-expr<1.2,>=1.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (1.1.20)\n",
      "Requirement already satisfied: distributed==2024.12.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (2024.12.0)\n",
      "Requirement already satisfied: bokeh>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (3.6.2)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (3.1.4)\n",
      "Requirement already satisfied: msgpack>=1.0.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from distributed==2024.12.0->dask[complete]) (1.1.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /Users/albertzhemukov/Library/Python/3.13/lib/python/site-packages (from distributed==2024.12.0->dask[complete]) (6.1.0)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from distributed==2024.12.0->dask[complete]) (2.4.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from distributed==2024.12.0->dask[complete]) (3.0.0)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /Users/albertzhemukov/Library/Python/3.13/lib/python/site-packages (from distributed==2024.12.0->dask[complete]) (6.4.2)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from distributed==2024.12.0->dask[complete]) (2.2.3)\n",
      "Requirement already satisfied: zict>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from distributed==2024.12.0->dask[complete]) (3.0.0)\n",
      "Requirement already satisfied: contourpy>=1.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from bokeh>=3.1.0->dask[complete]) (1.3.0)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from bokeh>=3.1.0->dask[complete]) (11.0.0)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from bokeh>=3.1.0->dask[complete]) (2024.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jinja2>=2.10.3->dask[complete]) (3.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas>=2.0->dask[complete]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas>=2.0->dask[complete]) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas>=2.0->dask[complete]) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas>=2.0->dask[complete]) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"dask[complete]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8889c3db692cd4c",
   "metadata": {},
   "source": [
    "# Dask Array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b487daee63ae4be",
   "metadata": {},
   "source": [
    "Dask Array — это масштабируемая версия массива NumPy, которая работает с массивами, превышающими объем оперативной памяти, и распределяет вычисления между несколькими ядрами или машинами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2550f73cc6ab3f8a",
   "metadata": {},
   "source": [
    "- Dask Array поддерживает API NumPy, что позволяет использовать знакомые функции и методы.\n",
    "\n",
    "- Массивы разбиваются на более мелкие блоки, которые обрабатываются независимо.\n",
    "\n",
    "- Поддерживаются вычисления как на локальной машине, так и в распределенных системах."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207fa0ba0343c15a",
   "metadata": {},
   "source": [
    "Рассмотрим для начала пример из документации:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43640558f269a226",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9c302565998fe2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T09:20:15.047610Z",
     "start_time": "2024-12-10T09:18:56.796302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dask.array as da\n",
    "\n",
    "# Создаем обычный NumPy массив размером 10x10\n",
    "x = np.arange(100).reshape(10, 10)\n",
    "# Преобразуем NumPy массив в Dask Array с чанками (разбиением) 5x5\n",
    "dask_array = da.from_array(x, chunks=(5, 5))\n",
    "\n",
    "result = dask_array.mean()\n",
    "print(result.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4f71c7f6acb2ef",
   "metadata": {},
   "source": [
    "Разберемся, что здесь вообще происходит.\n",
    "\n",
    "Вместо того чтобы обрабатывать весь массив сразу, Dask делит его на чанки, что позволяет работать с большими данными, превышающими оперативную память.\n",
    "Выполнение вычислений параллелизуется, что ускоряет процесс на многопроцессорных системах."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e711b16ca80a79",
   "metadata": {},
   "source": [
    "![dask-array](images/dask-array-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359d8272913d6ddb",
   "metadata": {},
   "source": [
    "На изображении показано, как Dask Array разбивает большой массив на более мелкие части — чанки. Каждый чанк представляет собой отдельный NumPy массив."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423a12fa05a482a5",
   "metadata": {},
   "source": [
    "Пусть нам нужно вычислить индекс растительности NDVI для спутниковых данных, представляющих 10 сцен, каждая из которых состоит из двух каналов: ближний инфракрасный (NIR) и красный (Red). NDVI является важным показателем для анализа растительности, так как он показывает степень активности фотосинтеза в растительных покровах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "512dad63391bb196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDVI сцены 1, пиксель [0, 0]: 0.38848815090547295\n"
     ]
    }
   ],
   "source": [
    "# Генерируем массив данных: снимки 10000x10000 (10 сцен, 2 канала: NIR и Red)\n",
    "satellite_data = da.random.random((10, 2, 10_000, 10_000), chunks=(1, 2, 5000, 5000))\n",
    "\n",
    "# Разделяем каналы\n",
    "nir = satellite_data[:, 0, :, :]  # Near Infrared\n",
    "red = satellite_data[:, 1, :, :]  # Red\n",
    "\n",
    "# Вычисляем NDVI\n",
    "ndvi = (nir - red) / (nir + red)\n",
    "\n",
    "print(\"NDVI сцены 1, пиксель [0, 0]:\", ndvi[0, 0, 0].compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1b8f50183b37",
   "metadata": {},
   "source": [
    "Попробуем сделать то же самое с NumPy (этот код ниже лучше не запускать - у меня, например, все 16 гигов оперативки кончились моментально)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8cc5a90c4993bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерируем аналогичный массив данных: снимки 10000x10000 (10 сцен, 2 канала)\n",
    "\n",
    "# numpy_satellite_data = np.random.random((10, 2, 10_000, 10_000))\n",
    "\n",
    "# Разделяем каналы\n",
    "# nir = numpy_satellite_data[:, 0, :, :]  # Near Infrared\n",
    "# red = numpy_satellite_data[:, 1, :, :]  # Red\n",
    "\n",
    "# Вычисляем NDVI\n",
    "# try:\n",
    "    # ndvi = (nir - red) / (nir + red)\n",
    "    # print(\"NDVI сцены 1, пиксель [0, 0]:\", ndvi[0, 0, 0])\n",
    "# except MemoryError:\n",
    "    # print(\"NumPy не справился: данные слишком велики для оперативной памяти.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874d3988ce4eef82",
   "metadata": {},
   "source": [
    "Таким образом, мы посмотрели как работают массивы в Dask. Теперь потыкаем Bag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0958d805",
   "metadata": {},
   "source": [
    "## Dask Bag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded21455",
   "metadata": {},
   "source": [
    "Dask Bag — это компонент библиотеки Dask, предназначенный для параллельной обработки коллекций произвольных Python объектов с использованием операций, таких как map, filter, fold и groupby. Он эффективно работает с неструктурированными или полуструктурированными данными, такими как текстовые файлы, лог-файлы, JSON-записи или пользовательские объекты Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd25dd3",
   "metadata": {},
   "source": [
    "Рассмотрим задачу подсчета наиболее частых слов в наборе текстовых файлов (например, анализ лог-файлов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ab1814452ad15f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/distributed/node.py:187: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 56389 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:56389/status\n",
      "Топ-10 самых частых элементов: [('4545', 24), ('3937', 23), ('1611', 22), ('1862', 21), ('986', 21), ('3911', 21), ('2270', 21), ('1974', 20), ('2447', 20), ('1742', 20)]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "from datetime import datetime\n",
    "from dask.distributed import Client\n",
    "import dask.bag as db\n",
    "\n",
    "# Запуск Dask Dashboard\n",
    "client = Client()\n",
    "print(client.dashboard_link)\n",
    "\n",
    "# Функция для генерации случайной строки логов\n",
    "def generate_log_line():\n",
    "    ip = \".\".join(str(random.randint(0, 255)) for _ in range(4))  # Генерация случайного IP-адреса\n",
    "    timestamp = datetime.now().strftime('%d/%b/%Y:%H:%M:%S')  # Текущее время в формате логов\n",
    "    http_methods = [\"GET\", \"POST\", \"PUT\", \"DELETE\", \"PATCH\"]\n",
    "    method = random.choice(http_methods)  # Случайный HTTP-метод\n",
    "    url = \"/\" + \"/\".join(\n",
    "        ''.join(random.choices(string.ascii_lowercase, k=random.randint(3, 10))) for _ in range(3)\n",
    "    )  # Случайный URL\n",
    "    status = random.choice([200, 201, 400, 404, 500])  # Случайный статус ответа\n",
    "    response_time = random.uniform(0.1, 5.0)  # Время ответа в секундах\n",
    "\n",
    "    return f'{ip} - - [{timestamp}] \"{method} {url} HTTP/1.1\" {status} {int(response_time * 1000)}'\n",
    "\n",
    "# Обработка строк логов: выделение частей лога для анализа\n",
    "def process_log_line(line):\n",
    "    parts = line.split()\n",
    "    if len(parts) < 9:  # Проверка на валидность строки лога\n",
    "        return []\n",
    "    ip = parts[0]  # IP-адрес\n",
    "    method = parts[5].strip('\"')  # HTTP-метод\n",
    "    status = parts[8]  # Статус ответа\n",
    "    return [ip, method, status]\n",
    "\n",
    "# Генерация 50,000 строк логов\n",
    "num_lines = 50_000\n",
    "chunk_size = 10_000\n",
    "data = db.from_sequence([generate_log_line() for _ in range(num_lines)], npartitions=num_lines // chunk_size)\n",
    "\n",
    "# Обработка логов\n",
    "processed_data = data.map(process_log_line).flatten()  # Обрабатываем строки логов\n",
    "\n",
    "# Подсчитываем частоту каждого элемента\n",
    "element_counts = processed_data.frequencies()\n",
    "\n",
    "# Получаем топ-10 самых частых элементов\n",
    "top_10_elements = element_counts.topk(10, key=lambda x: x[1])\n",
    "print(\"Топ-10 самых частых элементов:\", top_10_elements.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1978f36e",
   "metadata": {},
   "source": [
    "Dask Bag напоминает параллельную версию библиотеки PyToolz или Python-эквивалент RDD из Apache Spark. Благодаря ленивой обработке и использованию итераторов, Dask Bag позволяет работать с данными, превышающими объем оперативной памяти, и эффективно задействовать ресурсы нескольких ядер или даже машин."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77afd6ea6532be6",
   "metadata": {},
   "source": [
    "## Как проверить прогресс выполнения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effe7b2abd2de956",
   "metadata": {},
   "source": [
    "Dask поддерживает визуализацию выполнения задач через инструмент Dask Dashboard. Вы можете запустить его, добавив следующие строки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a557bdc9facf8061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:54553/status\n"
     ]
    }
   ],
   "source": [
    "# from dask.distributed import Client\n",
    "# client = Client()\n",
    "print(client.dashboard_link)  # Откроет ссылку на дашборд"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9163f0a0322ab02",
   "metadata": {},
   "source": [
    "После запуска вы сможете видеть статус выполнения задач в режиме реального времени."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
