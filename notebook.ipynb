{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c74e8b3",
   "metadata": {},
   "source": [
    "# Deep Python 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d85654",
   "metadata": {},
   "source": [
    "Автор: Жемуков Альберт Артурович\n",
    "\n",
    "Cтудент БПМИ 239"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725451a0",
   "metadata": {},
   "source": [
    "## Предисловие"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37488148",
   "metadata": {},
   "source": [
    "После самостоятельного изучения библиотеки, ее документации и гайдов по ней, я создал этот доклад. Вместо исключительного объяснения как работает каждый метод, я постарался показать это преимущественно на примерах (котрые постарался сделать достаточно интересными). То есть, доклад это своего рода выжимка != документация. Он создан именно с целью потыкать код и при этом понять, что происходит. Другими словами, фундаментальные объяснения, которые есть в документации здесь вряд ли будут. Доклад построен на практических примерах."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1de893a",
   "metadata": {},
   "source": [
    "With that out of the way, погнали дальше!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84124c9",
   "metadata": {},
   "source": [
    "![chillguy](images/justachillguy-v0-cnvsm1t7p82e1.png.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaabe7791de8e2",
   "metadata": {},
   "source": [
    "## Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19970fa",
   "metadata": {},
   "source": [
    "![logo](images/images.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0866b873e18ef1",
   "metadata": {},
   "source": [
    "Dask - это библиотека для параллельных вычислений и масштабирования. Допустим, что Numpy не справляется с объемом данных, который нам нужно будет обработать. В таком случае естественной альтернативой как раз станет Dask. Dask предоставляет возможность работать с данными, которые превышают объем оперативной памяти, и эффективно использовать ресурсы как на локальной машине, так и на кластере. Библиотека позволяет масштабировать код Python с минимальными изменениями."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c84c9c4",
   "metadata": {},
   "source": [
    "## Немного теории"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eaa4cf",
   "metadata": {},
   "source": [
    "Кластер — это группа компьютеров, объединённых вместе для совместного выполнения задач. Они работают как единая система и часто используются для увеличения производительности, масштабируемости и надежности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fa06e5",
   "metadata": {},
   "source": [
    "Кластер работает благодаря взаимодействию нескольких компонентов. Контроллер (мастер-узел) отвечает за управление распределением задач между узлами, отслеживает их состояние и следит за использованием ресурсов, таких как память и процессоры. Рабочие узлы (worker-узлы) выполняют задачи, которые им передает контроллер, обрабатывают данные или производят вычисления. Все узлы в кластере связаны между собой через локальную или облачную сеть, что позволяет им обмениваться данными и координировать выполнение задач в реальном времени."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab964af1",
   "metadata": {},
   "source": [
    "Dask поддерживает работу на локальном компьютере, но его ключевая сила — распределенные вычисления на кластерах."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c368a1d",
   "metadata": {},
   "source": [
    "Кластеры — это основа современных вычислений, особенно в сфере анализа данных, машинного обучения и высокопроизводительных вычислений."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0472af2d568ca8d",
   "metadata": {},
   "source": [
    "## Полезные ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29291f71cc75d8d2",
   "metadata": {},
   "source": [
    "[Официальная документация либы](https://docs.dask.org/en/stable/)\n",
    "\n",
    "[Официальный туториал](https://tutorial.dask.org/00_overview.html)\n",
    "\n",
    "[Офигенная статья на Хабре](https://habr.com/ru/companies/otus/articles/759552/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38d1de40e22ccbd",
   "metadata": {},
   "source": [
    "## Установка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1454e34d3ca316",
   "metadata": {},
   "source": [
    "Здесь все стандартно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T09:18:47.576563Z",
     "start_time": "2024-12-10T09:18:46.714320Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dask[complete] in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2024.12.0)\n",
      "Requirement already satisfied: click>=8.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dask[complete]) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dask[complete]) (3.1.0)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dask[complete]) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dask[complete]) (23.2)\n",
      "Requirement already satisfied: partd>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dask[complete]) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dask[complete]) (6.0.1)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dask[complete]) (1.0.0)\n",
      "Requirement already satisfied: pyarrow>=14.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dask[complete]) (18.1.0)\n",
      "Collecting lz4>=4.3.2 (from dask[complete])\n",
      "  Downloading lz4-4.3.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: locket in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from partd>=1.4.0->dask[complete]) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.24 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dask[complete]) (1.26.0)\n",
      "Requirement already satisfied: pandas>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dask[complete]) (2.2.3)\n",
      "Requirement already satisfied: dask-expr<1.2,>=1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dask[complete]) (1.1.20)\n",
      "Requirement already satisfied: distributed==2024.12.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dask[complete]) (2024.12.0)\n",
      "Collecting bokeh>=3.1.0 (from dask[complete])\n",
      "  Using cached bokeh-3.6.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from dask[complete]) (3.1.3)\n",
      "Requirement already satisfied: msgpack>=1.0.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed==2024.12.0->dask[complete]) (1.1.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed==2024.12.0->dask[complete]) (5.9.5)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed==2024.12.0->dask[complete]) (2.4.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed==2024.12.0->dask[complete]) (3.0.0)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed==2024.12.0->dask[complete]) (6.3.3)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed==2024.12.0->dask[complete]) (2.2.1)\n",
      "Requirement already satisfied: zict>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from distributed==2024.12.0->dask[complete]) (3.0.0)\n",
      "Collecting contourpy>=1.2 (from bokeh>=3.1.0->dask[complete])\n",
      "  Downloading contourpy-1.3.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.4 kB)\n",
      "Collecting pillow>=7.1.0 (from bokeh>=3.1.0->dask[complete])\n",
      "  Downloading pillow-11.0.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Collecting xyzservices>=2021.09.1 (from bokeh>=3.1.0->dask[complete])\n",
      "  Using cached xyzservices-2024.9.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2>=2.10.3->dask[complete]) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=2.0->dask[complete]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=2.0->dask[complete]) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=2.0->dask[complete]) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=2.0->dask[complete]) (1.16.0)\n",
      "Downloading lz4-4.3.3-cp312-cp312-macosx_11_0_arm64.whl (212 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.4/212.4 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached bokeh-3.6.2-py3-none-any.whl (6.9 MB)\n",
      "Downloading contourpy-1.3.1-cp312-cp312-macosx_11_0_arm64.whl (255 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.4/255.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.0.0-cp312-cp312-macosx_11_0_arm64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached xyzservices-2024.9.0-py3-none-any.whl (85 kB)\n",
      "Installing collected packages: xyzservices, pillow, lz4, contourpy, bokeh\n",
      "Successfully installed bokeh-3.6.2 contourpy-1.3.1 lz4-4.3.3 pillow-11.0.0 xyzservices-2024.9.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"dask[complete]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8889c3db692cd4c",
   "metadata": {},
   "source": [
    "## Dask Array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b487daee63ae4be",
   "metadata": {},
   "source": [
    "Dask Array — это масштабируемая версия массива NumPy, которая работает с массивами, превышающими объем оперативной памяти, и распределяет вычисления между несколькими ядрами или машинами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2550f73cc6ab3f8a",
   "metadata": {},
   "source": [
    "- Dask Array поддерживает API NumPy, что позволяет использовать знакомые функции и методы.\n",
    "\n",
    "- Массивы разбиваются на более мелкие блоки, которые обрабатываются независимо.\n",
    "\n",
    "- Поддерживаются вычисления как на локальной машине, так и в распределенных системах."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207fa0ba0343c15a",
   "metadata": {},
   "source": [
    "Рассмотрим для начала пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9c302565998fe2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T09:20:15.047610Z",
     "start_time": "2024-12-10T09:18:56.796302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dask.array as da\n",
    "\n",
    "# Создаем обычный NumPy массив размером 10x10\n",
    "x = np.arange(100).reshape(10, 10)\n",
    "# Преобразуем NumPy массив в Dask Array с чанками (разбиением) 5x5\n",
    "dask_array = da.from_array(x, chunks=(5, 5))\n",
    "\n",
    "result = dask_array.mean()\n",
    "print(result.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4f71c7f6acb2ef",
   "metadata": {},
   "source": [
    "Разберемся, что здесь вообще происходит.\n",
    "\n",
    "Вместо того чтобы обрабатывать весь массив сразу, Dask делит его на чанки, что позволяет работать с большими данными, превышающими оперативную память.\n",
    "Выполнение вычислений параллелизуется, что ускоряет процесс на многопроцессорных системах."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e711b16ca80a79",
   "metadata": {},
   "source": [
    "![dask-array](images/dask-array-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359d8272913d6ddb",
   "metadata": {},
   "source": [
    "На изображении показано, как Dask Array разбивает большой массив на более мелкие части — чанки. Каждый чанк представляет собой отдельный NumPy массив."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423a12fa05a482a5",
   "metadata": {},
   "source": [
    "Пусть нам нужно вычислить индекс растительности NDVI для спутниковых данных, представляющих 10 сцен, каждая из которых состоит из двух каналов: ближний инфракрасный (NIR) и красный (Red). NDVI является важным показателем для анализа растительности, так как он показывает степень активности фотосинтеза в растительных покровах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "512dad63391bb196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDVI сцены 1, пиксель [0, 0]: 0.4115605267861062\n"
     ]
    }
   ],
   "source": [
    "# Генерируем массив данных: снимки 10000x10000 (10 сцен, 2 канала: NIR и Red)\n",
    "satellite_data = da.random.random((10, 2, 10_000, 10_000), chunks=(1, 2, 5000, 5000))\n",
    "\n",
    "# Разделяем каналы\n",
    "nir = satellite_data[:, 0, :, :]  # Near Infrared\n",
    "red = satellite_data[:, 1, :, :]  # Red\n",
    "\n",
    "# Вычисляем NDVI\n",
    "ndvi = (nir - red) / (nir + red)\n",
    "\n",
    "print(\"NDVI сцены 1, пиксель [0, 0]:\", ndvi[0, 0, 0].compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1b8f50183b37",
   "metadata": {},
   "source": [
    "Попробуем сделать то же самое с NumPy (этот код ниже лучше не запускать)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8cc5a90c4993bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерируем аналогичный массив данных: снимки 10000x10000 (10 сцен, 2 канала)\n",
    "\n",
    "# numpy_satellite_data = np.random.random((10, 2, 10_000, 10_000))\n",
    "\n",
    "# Разделяем каналы\n",
    "# nir = numpy_satellite_data[:, 0, :, :]  # Near Infrared\n",
    "# red = numpy_satellite_data[:, 1, :, :]  # Red\n",
    "\n",
    "# Вычисляем NDVI\n",
    "# try:\n",
    "    # ndvi = (nir - red) / (nir + red)\n",
    "    # print(\"NDVI сцены 1, пиксель [0, 0]:\", ndvi[0, 0, 0])\n",
    "# except MemoryError:\n",
    "    # print(\"NumPy не справился: данные слишком велики для оперативной памяти.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874d3988ce4eef82",
   "metadata": {},
   "source": [
    "Таким образом, мы посмотрели как работают массивы в Dask. Теперь потыкаем Bag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0958d805",
   "metadata": {},
   "source": [
    "## Dask Bag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded21455",
   "metadata": {},
   "source": [
    "Dask Bag — это компонент библиотеки Dask, предназначенный для параллельной обработки коллекций произвольных Python объектов с использованием операций, таких как map, filter, fold и groupby. Он эффективно работает с неструктурированными или полуструктурированными данными, такими как текстовые файлы, лог-файлы, JSON-записи или пользовательские объекты Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd25dd3",
   "metadata": {},
   "source": [
    "Рассмотрим задачу подсчета наиболее частых слов в наборе текстовых файлов (например, анализ лог-файлов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ab1814452ad15f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/distributed/node.py:187: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 59459 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:59459/status\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/distributed/client.py:3371: UserWarning: Sending large graph of size 87.57 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider loading the data with Dask directly\n",
      " or using futures or delayed objects to embed the data into the graph without repetition.\n",
      "See also https://docs.dask.org/en/stable/best-practices.html#load-data-with-dask for more information.\n",
      "  warnings.warn(\n",
      "2024-12-10 20:05:45,554 - distributed.nanny - ERROR - Worker process died unexpectedly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-10 самых частых элементов: [('3728', 260), ('1555', 251), ('1634', 248), ('1466', 247), ('2510', 247), ('2847', 247), ('1764', 247), ('1526', 246), ('4007', 246), ('4652', 245)]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "from datetime import datetime\n",
    "from dask.distributed import Client\n",
    "import dask.bag as db\n",
    "\n",
    "# Запуск Dask Dashboard\n",
    "client = Client()\n",
    "print(client.dashboard_link)\n",
    "\n",
    "# Функция для генерации случайной строки логов\n",
    "def generate_log_line():\n",
    "    ip = \".\".join(str(random.randint(0, 255)) for _ in range(4))  # Генерация случайного IP-адреса\n",
    "    timestamp = datetime.now().strftime('%d/%b/%Y:%H:%M:%S')  # Текущее время в формате логов\n",
    "    http_methods = [\"GET\", \"POST\", \"PUT\", \"DELETE\", \"PATCH\"]\n",
    "    method = random.choice(http_methods)  # Случайный HTTP-метод\n",
    "    url = \"/\" + \"/\".join(\n",
    "        ''.join(random.choices(string.ascii_lowercase, k=random.randint(3, 10))) for _ in range(3)\n",
    "    )  # Случайный URL\n",
    "    status = random.choice([200, 201, 400, 404, 500])  # Случайный статус ответа\n",
    "    response_time = random.uniform(0.1, 5.0)  # Время ответа в секундах\n",
    "\n",
    "    return f'{ip} - - [{timestamp}] \"{method} {url} HTTP/1.1\" {status} {int(response_time * 1000)}'\n",
    "\n",
    "# Обработка строк логов: выделение частей лога для анализа\n",
    "def process_log_line(line):\n",
    "    parts = line.split()\n",
    "    if len(parts) < 9:  # Проверка на валидность строки лога\n",
    "        return []\n",
    "    ip = parts[0]  # IP-адрес\n",
    "    method = parts[5].strip('\"')  # HTTP-метод\n",
    "    status = parts[8]  # Статус ответа\n",
    "    return [ip, method, status]\n",
    "\n",
    "# Генерация 1 миллиона строк логов с ленивым генератором\n",
    "num_lines = 1 * 10 ** 6\n",
    "chunk_size = 1 * 10 ** 5\n",
    "data = db.from_sequence((generate_log_line() for _ in range(num_lines)), npartitions=num_lines // chunk_size)\n",
    "\n",
    "# Обработка логов\n",
    "processed_data = data.map(process_log_line).flatten()  # Обрабатываем строки логов\n",
    "\n",
    "# Подсчитываем частоту каждого элемента\n",
    "element_counts = processed_data.frequencies()\n",
    "\n",
    "# Получаем топ-10 самых частых элементов\n",
    "top_10_elements = element_counts.topk(10, key=lambda x: x[1])\n",
    "print(\"Топ-10 самых частых элементов:\", top_10_elements.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1978f36e",
   "metadata": {},
   "source": [
    "Dask Bag напоминает параллельную версию библиотеки PyToolz или Python-эквивалент RDD из Apache Spark. Благодаря ленивой обработке и использованию итераторов, Dask Bag позволяет работать с данными, превышающими объем оперативной памяти, и эффективно задействовать ресурсы нескольких ядер или даже машин."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77afd6ea6532be6",
   "metadata": {},
   "source": [
    "## Прогресс выполнения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effe7b2abd2de956",
   "metadata": {},
   "source": [
    "Dask поддерживает визуализацию выполнения задач через инструмент Dask Dashboard. Вы можете запустить его, добавив следующие строки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a557bdc9facf8061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:59459/status\n"
     ]
    }
   ],
   "source": [
    "# from dask.distributed import Client\n",
    "# client = Client()\n",
    "print(client.dashboard_link)  # Откроет ссылку на дашборд"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9163f0a0322ab02",
   "metadata": {},
   "source": [
    "После запуска вы сможете видеть статус выполнения задач в режиме реального времени."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b810fb8",
   "metadata": {},
   "source": [
    "## Dask DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8973da45",
   "metadata": {},
   "source": [
    "Dask DataFrame — это инструмент для работы с большими табличными данными, который позволяет масштабировать вычисления на основе библиотеки pandas. Если данные слишком велики для обработки в памяти или вычисления занимают слишком много времени, Dask DataFrame предоставляет решение, которое позволяет эффективно использовать ресурсы компьютера или распределенного кластера."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea9e9a7",
   "metadata": {},
   "source": [
    "API Dask DataFrame почти полностью повторяет API pandas. Большинство методов pandas можно использовать с Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89f03a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a    b\n",
      "0  0  100\n",
      "1  1  101\n",
      "2  2  102\n",
      "3  3  103\n",
      "4  4  104\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Создаем pandas DataFrame\n",
    "data = pd.DataFrame({'a': range(100), 'b': range(100, 200)})\n",
    "\n",
    "# Преобразуем pandas DataFrame в Dask DataFrame\n",
    "dask_df = dd.from_pandas(data, npartitions=4)\n",
    "print(dask_df.head())  # Вывод первых строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea304c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 CSV files created in 'data/'\n",
      "3 PARQUET files created in 'data/'\n",
      "3 JSON files created in 'data/'\n",
      "Пример данных:\n",
      "   col1    col2\n",
      "0     0  text_0\n",
      "1     1  text_1\n",
      "2     2  text_2\n",
      "3     3  text_3\n",
      "4     4  text_4\n",
      "----------------------------------------\n",
      "Пример данных:\n",
      "   col1    col2\n",
      "0     0  text_0\n",
      "1     1  text_1\n",
      "2     2  text_2\n",
      "3     3  text_3\n",
      "4     4  text_4\n",
      "----------------------------------------\n",
      "Пример данных:\n",
      "   col1    col2\n",
      "0     0  text_0\n",
      "1     1  text_1\n",
      "2     2  text_2\n",
      "3     3  text_3\n",
      "4     4  text_4\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Создаем тестовые данные\n",
    "def create_mock_data(file_type, directory=\"data\", num_files=3):\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    for i in range(num_files):\n",
    "        data = pd.DataFrame({\n",
    "            \"col1\": range(10 * i, 10 * (i + 1)),\n",
    "            \"col2\": [f\"text_{j}\" for j in range(10)],\n",
    "        })\n",
    "        file_path = os.path.join(directory, f\"file_{i}.{file_type}\")\n",
    "        if file_type == \"csv\":\n",
    "            data.to_csv(file_path, index=False)\n",
    "        elif file_type == \"parquet\":\n",
    "            data.to_parquet(file_path, index=False)\n",
    "        elif file_type == \"json\":\n",
    "            data.to_json(file_path, orient=\"records\", lines=True)\n",
    "    print(f\"{num_files} {file_type.upper()} files created in '{directory}/'\")\n",
    "\n",
    "# Чтение mock-файлов с помощью Dask\n",
    "def read_mock_files(file_type, directory=\"data\"):\n",
    "    if file_type == \"csv\":\n",
    "        df = dd.read_csv(f\"{directory}/*.csv\")\n",
    "    elif file_type == \"parquet\":\n",
    "        df = dd.read_parquet(f\"{directory}/*.parquet\")\n",
    "    elif file_type == \"json\":\n",
    "        df = dd.read_json(f\"{directory}/*.json\")\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type\")\n",
    "    \n",
    "    print(\"Пример данных:\")\n",
    "    print(df.head())\n",
    "    print(\"-\"*40)\n",
    "\n",
    "# Создаем mock CSV, Parquet и JSON файлы\n",
    "create_mock_data(\"csv\")\n",
    "create_mock_data(\"parquet\")\n",
    "create_mock_data(\"json\")\n",
    "\n",
    "# Читаем файлы и выводим пример данных\n",
    "read_mock_files(\"csv\")\n",
    "read_mock_files(\"parquet\")\n",
    "read_mock_files(\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4a36b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   col1    col2\n",
      "0     0  text_0\n",
      "1     1  text_1\n",
      "2     2  text_2\n",
      "3     3  text_3\n",
      "4     4  text_4\n",
      "<class 'dask_expr.DataFrame'>\n",
      "Columns: 2 entries, col1 to col2\n",
      "dtypes: int64(1), string(1)None\n",
      "Dask DataFrame Structure:\n",
      "                  col1\n",
      "npartitions=1         \n",
      "               float64\n",
      "                   ...\n",
      "Dask Name: to_frame, 6 expressions\n",
      "Expr=ToFrame(frame=ArrowStringConversion(frame=FromDelayed(e8b67da))['col1'].describenumeric(split_every=False))\n"
     ]
    }
   ],
   "source": [
    "df = dd.read_json('data/*.json')\n",
    "\n",
    "print(df.head()) # Первые строки\n",
    "print(df.info()) # Информация о DataFrame\n",
    "print(df.describe()) # Статистика"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9e8996",
   "metadata": {},
   "source": [
    "Если данные часто используются, их можно сохранить в оперативной памяти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db454ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "persisted_df = df.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468c63ff",
   "metadata": {},
   "source": [
    "Dask поддерживает запись данных в различные форматы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a22d8a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запись в CSV\n",
    "df.to_csv('output/*.csv', index=False)\n",
    "\n",
    "# Запись в Parquet\n",
    "df.to_parquet('output/', engine='pyarrow') # директория output в репозитории должна обновиться"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33201693",
   "metadata": {},
   "source": [
    "## Dask Delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b859261f",
   "metadata": {},
   "source": [
    "Dask Delayed — это инструмент для параллельного выполнения пользовательских алгоритмов, которые не вписываются в стандартные высокоуровневые коллекции Dask, такие как Array, DataFrame или Bag. С помощью Dask Delayed можно создавать графы задач (task graphs), описывающие порядок выполнения функций, и выполнять их параллельно. Этот подход особенно полезен для вычислений, где присутствует явный параллелизм, но нет структуры данных, подходящей для стандартных коллекций Dask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81cbdc3",
   "metadata": {},
   "source": [
    "Вместо немедленного выполнения функции, Dask Delayed откладывает её выполнение и строит граф задач. Граф содержит функции, их аргументы и зависимости между ними. После построения графа задачи могут быть выполнены параллельно с использованием планировщиков Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e4bb08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "from dask import delayed\n",
    "\n",
    "def inc(x):\n",
    "    return x + 1\n",
    "\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "x = delayed(inc)(1) # отложим выполнение на 1\n",
    "y = delayed(inc)(2) # отложим выполнение  на 2\n",
    "z = delayed(add)(x, y) # объект Delayed, содержащий граф задач\n",
    "print(z.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4d863f",
   "metadata": {},
   "source": [
    "Для упрощения кода dask.delayed часто также используется как декоратор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d89bfa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@delayed\n",
    "def triple(x):\n",
    "    return x * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1e5ce0",
   "metadata": {},
   "source": [
    "Если задача зависит от побочного эффекта другой задачи, используется dask.graph_manipulation.bind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22f5fd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "from dask.graph_manipulation import bind\n",
    "\n",
    "DATA = []\n",
    "\n",
    "@delayed\n",
    "def add_data(x):\n",
    "    DATA.append(x)\n",
    "\n",
    "@delayed\n",
    "def sum_data(x):\n",
    "    return sum(DATA) + x\n",
    "\n",
    "a = add_data(1)\n",
    "b = add_data(2)\n",
    "c = bind(sum_data, [a, b])(3)\n",
    "print(c.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b336297",
   "metadata": {},
   "source": [
    "Рассмотрим сценарий, где необходимо выполнить сложную цепочку вычислений над несколькими наборами данных, включающую загрузку данных из нескольких источников, их предварительную обработку, выполнение вычислений и сохранение результатов. Еще добавим зависимости, которые требуют выполнения задач в определенном порядке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db21d766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружаем данные из source_1\n",
      "Фильтруем данные с порогом 50\n",
      "Выполняем вычисления\n",
      "Загружаем данные из source_2\n",
      "Фильтруем данные с порогом 50\n",
      "Выполняем вычисления\n",
      "Агрегация данных\n",
      "Сохраняем результат в examples/result.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Результат сохранен в examples/result.txt'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Имитация загрузки данных\n",
    "@delayed\n",
    "def load_data(source):\n",
    "    time.sleep(random.uniform(0.5, 1.5))  # Имитация задержки\n",
    "    print(f\"Загружаем данные из {source}\")\n",
    "    return [random.randint(1, 100) for _ in range(10)]  # Генерация данных\n",
    "\n",
    "# Обработка данных: фильтрация\n",
    "@delayed\n",
    "def filter_data(data, threshold):\n",
    "    print(f\"Фильтруем данные с порогом {threshold}\")\n",
    "    return [x for x in data if x > threshold]\n",
    "\n",
    "# Сложные вычисления: увеличение, затем умножение\n",
    "@delayed\n",
    "def computation(data):\n",
    "    print(\"Выполняем вычисления\")\n",
    "    time.sleep(1)  # Имитация тяжелых вычислений\n",
    "    return [x * 2 + 1 for x in data]\n",
    "\n",
    "# Финальная агрегация\n",
    "@delayed\n",
    "def aggregate(data1, data2):\n",
    "    print(\"Агрегация данных\")\n",
    "    return sum(data1) + sum(data2)\n",
    "\n",
    "# Сохранение результата\n",
    "@delayed\n",
    "def save_result(result, filename):\n",
    "    print(f\"Сохраняем результат в {filename}\")\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(str(result))\n",
    "    return f\"Результат сохранен в {filename}\"\n",
    "\n",
    "# Создание графа задач\n",
    "sources = [\"source_1\", \"source_2\"]\n",
    "\n",
    "# Загрузка данных\n",
    "data_1 = load_data(sources[0])\n",
    "data_2 = load_data(sources[1])\n",
    "\n",
    "# Обработка данных\n",
    "filtered_data_1 = filter_data(data_1, threshold=50)\n",
    "filtered_data_2 = filter_data(data_2, threshold=50)\n",
    "\n",
    "# Сложные вычисления\n",
    "computed_data_1 = computation(filtered_data_1)\n",
    "computed_data_2 = computation(filtered_data_2)\n",
    "\n",
    "# Агрегация данных\n",
    "final_result = aggregate(computed_data_1, computed_data_2)\n",
    "\n",
    "# Сохранение результатов\n",
    "save_task = save_result(final_result, \"examples/result.txt\")\n",
    "\n",
    "# Выполнение графа задач\n",
    "save_task.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da41ec2c",
   "metadata": {},
   "source": [
    "Добавим визуализацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4a56c11",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No visualization engine detected, please install graphviz or ipycytoscape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# %pip install graphviz\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# brew install graphviz\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43msave_task\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrankdir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLR\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/dask/base.py:298\u001b[0m, in \u001b[0;36mDaskMethodsMixin.visualize\u001b[0;34m(self, filename, format, optimize_graph, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisualize\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmydask\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, optimize_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    255\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Render the computation of this object's task graph using graphviz.\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \n\u001b[1;32m    257\u001b[0m \u001b[38;5;124;03m    Requires ``graphviz`` to be installed.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;124;03m    https://docs.dask.org/en/latest/optimize.html\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisualize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimize_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimize_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/dask/base.py:757\u001b[0m, in \u001b[0;36mvisualize\u001b[0;34m(filename, traverse, optimize_graph, maxval, engine, *args, **kwargs)\u001b[0m\n\u001b[1;32m    753\u001b[0m args, _ \u001b[38;5;241m=\u001b[39m unpack_collections(\u001b[38;5;241m*\u001b[39margs, traverse\u001b[38;5;241m=\u001b[39mtraverse)\n\u001b[1;32m    755\u001b[0m dsk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(collections_to_dsk(args, optimize_graph\u001b[38;5;241m=\u001b[39moptimize_graph))\n\u001b[0;32m--> 757\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvisualize_dsk\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdsk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimize_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimize_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaxval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaxval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    765\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/dask/base.py:900\u001b[0m, in \u001b[0;36mvisualize_dsk\u001b[0;34m(dsk, filename, traverse, optimize_graph, maxval, o, engine, limit, **kwargs)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cytoscape_graph(dsk, filename\u001b[38;5;241m=\u001b[39mfilename, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    899\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 900\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    901\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo visualization engine detected, please install graphviz or ipycytoscape\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    902\u001b[0m     )\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVisualization engine \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not recognized\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No visualization engine detected, please install graphviz or ipycytoscape"
     ]
    }
   ],
   "source": [
    "# %pip install graphviz\n",
    "# brew install graphviz\n",
    "save_task.visualize(rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe71b906",
   "metadata": {},
   "source": [
    "По умолчанию Dask Delayed использует многопоточный планировщик (threaded scheduler) для минимизации затрат на передачу данных. Однако, если ваш код сильно зависит от GIL, например, при выполнении вычислений, доминирующих в чистом Python, или при использовании внешнего кода, который удерживает GIL, рекомендуется использовать другие планировщики."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e91385a",
   "metadata": {},
   "source": [
    "## Dask Futures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30a1d93",
   "metadata": {},
   "source": [
    "Dask Futures — это интерфейс для управления и выполнения задач в реальном времени, который позволяет легко масштабировать Python-код на кластере."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa59aa33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/distributed/node.py:187: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 59673 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "def square(x):\n",
    "    return x ** 2\n",
    "\n",
    "future = client.submit(square, 10)  # отправляем задачу\n",
    "print(future.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac9ef34",
   "metadata": {},
   "source": [
    "Dask Futures позволяет создавать задачи в реальном времени, даже в процессе выполнения других задач. Это может быть полезно, если объем работы неизвестен заранее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0fc8631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "futures = [client.submit(square, i) for i in range(10)]\n",
    "results = client.gather(futures)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81339a23",
   "metadata": {},
   "source": [
    "Dask Futures позволяет задавать зависимости между задачами вручную, обеспечивая выполнение задач в правильном порядке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55b5a814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "a = client.submit(square, 2)\n",
    "b = client.submit(square, 3)\n",
    "c = client.submit(add, a, b)\n",
    "print(c.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cd837a",
   "metadata": {},
   "source": [
    "Можно использовать методы map и gather для более эффективного управления несколькими задачами:\n",
    "\n",
    "1. clientmap применяет функцию к набору аргументов\n",
    "2. client.gather собирает результаты задач"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efeb8948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "futures = client.map(square, range(10))\n",
    "results = client.gather(futures)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f4f072",
   "metadata": {},
   "source": [
    "Futures можно использовать совместно с коллекциями Dask, чтобы смешивать статические и динамические вычисления."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66397490",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/distributed/node.py:187: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 59744 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Предварительный просмотр данных:\n",
      "   col1    col2\n",
      "0     0  text_0\n",
      "1     1  text_1\n",
      "2     2  text_2\n",
      "3     3  text_3\n",
      "4     4  text_4\n",
      "Сумма значений после фильтрации: 210\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "# тение данных с помощью Dask DataFrame\n",
    "ddf = dd.read_csv(\"data/*.csv\")\n",
    "print(\"Предварительный просмотр данных:\")\n",
    "print(ddf.head())\n",
    "\n",
    "filtered_ddf = ddf[ddf[\"col1\"] % 2 == 0]  # Фильтруем четные значения\n",
    "\n",
    "# Динамические вычисления с Dask Futures\n",
    "def compute_metric(partition):\n",
    "    # Вычисляем сумму значений в партии\n",
    "    return partition[\"col1\"].sum()\n",
    "\n",
    "# Преобразуем каждую партицию в Future с использованием клиента\n",
    "delayed_partitions = filtered_ddf.to_delayed()\n",
    "futures = [client.submit(compute_metric, part.compute()) for part in delayed_partitions]\n",
    "\n",
    "# Собираем результаты из Futures\n",
    "results = client.gather(futures)\n",
    "\n",
    "# Итоговая сумма значений\n",
    "total_sum = sum(results)\n",
    "print(f\"Сумма значений после фильтрации: {total_sum}\")\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e51855",
   "metadata": {},
   "source": [
    "## Dask ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81281cca",
   "metadata": {},
   "source": [
    "Dask предоставляет инструменты для масштабирования задач машинного обучения, позволяя работать с большими данными, распределять вычисления и эффективно использовать ресурсы кластера. Dask интегрируется с популярными библиотеками, такими как Scikit-learn, XGBoost, LightGBM, и поддерживает динамическое управление задачами с помощью интерфейса Futures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4cc3a5",
   "metadata": {},
   "source": [
    "Dask интегрируется с Optuna для распределенной оптимизации гиперпараметров. Это позволяет запускать большое количество экспериментов параллельно, синхронизируя результаты через планировщик Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0fdc41cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'optuna'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Установка необходимых библиотек\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# %pip install optuna dask[complete] scikit-learn\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moptuna\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_classification\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'optuna'"
     ]
    }
   ],
   "source": [
    "# Установка необходимых библиотек\n",
    "# %pip install optuna dask[complete] scikit-learn\n",
    "\n",
    "import optuna\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from dask.distributed import LocalCluster, Client, wait\n",
    "import numpy as np\n",
    "\n",
    "# Настройка Dask-кластера\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "\n",
    "# Загрузка более сложного датасета\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,  # Увеличенное число выборок\n",
    "    n_features=20,   # Увеличенное число признаков\n",
    "    n_informative=15,  # Число информативных признаков\n",
    "    n_redundant=5,   # Число избыточных признаков\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Деление данных на тренировочную и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Добавление шума в данные для повышения сложности\n",
    "X_train += np.random.normal(0, 0.1, X_train.shape)\n",
    "X_test += np.random.normal(0, 0.1, X_test.shape)\n",
    "\n",
    "# Функция для оценки модели\n",
    "def evaluate_model(model, test_data):\n",
    "    X_test, y_test = test_data\n",
    "    y_pred = model.predict(X_test)\n",
    "    return f1_score(y_test, y_pred, average='weighted')  # Используем F1-меру\n",
    "\n",
    "# Функция для оптимизации\n",
    "def objective(trial):\n",
    "    # Гиперпараметры для RandomForestClassifier\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),  # Расширенный диапазон\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 5, 20),          # Увеличенная глубина\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 15),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "    }\n",
    "    model = RandomForestClassifier(**params, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    score = evaluate_model(model, (X_test, y_test))\n",
    "    print(f\"Параметры: {params}, Результат: {score}\")\n",
    "    return score\n",
    "\n",
    "# Создаем исследование Optuna\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "# Параллельная оптимизация с использованием Dask\n",
    "def distributed_optimize():\n",
    "    trials = [study.ask() for _ in range(10)]  # Генерируем 10 испытаний\n",
    "    futures = [client.submit(objective, trial) for trial in trials]\n",
    "    wait(futures)  # Ожидание завершения всех задач\n",
    "\n",
    "    # Обработка результатов\n",
    "    for trial, future in zip(trials, futures):\n",
    "        try:\n",
    "            result = future.result()  # Получаем результат из Dask Future\n",
    "            study.tell(trial, result)  # Регистрация результата в Optuna\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка в задаче: {e}\")\n",
    "            study.tell(trial, float('-inf'))  # Обновляем результат с минимальным значением\n",
    "\n",
    "# Запуск распределенной оптимизации\n",
    "distributed_optimize()\n",
    "\n",
    "# Проверка завершенных итераций\n",
    "if len(study.trials) > 0:\n",
    "    if study.best_trial:\n",
    "        print(\"Лучший результат (F1):\", study.best_value)\n",
    "    else:\n",
    "        print(\"Нет успешных испытаний.\")\n",
    "else:\n",
    "    print(\"Нет завершенных испытаний.\")\n",
    "\n",
    "# Закрываем клиент\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a40fa0",
   "metadata": {},
   "source": [
    "Hyperband — это метод оптимизации гиперпараметров, который эффективно распределяет вычислительные ресурсы между множеством комбинаций параметров. Dask-ML включает встроенную реализацию HyperbandSearchCV, которая позволяет проводить масштабируемый поиск гиперпараметров в распределенной среде."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c500e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# этот код не работает на 3.13, нужно поставить 3.12\n",
    "\n",
    "from dask_ml.model_selection import HyperbandSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from distributed import Client\n",
    "\n",
    "# Настройка локального Dask-кластера\n",
    "client = Client()  # Запустит локальный кластер\n",
    "print(client)\n",
    "\n",
    "# Создание синтетического набора данных\n",
    "X, y = make_classification(n_samples=10000, n_features=20, random_state=42)\n",
    "\n",
    "# Определение модели и диапазона гиперпараметров\n",
    "clf = SGDClassifier(random_state=42)\n",
    "param_dist = {\n",
    "    'alpha': [0.0001, 0.001, 0.01],  # Регуляризация\n",
    "    'loss': ['hinge', 'log_loss'],        # Тип функции потерь\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],  # Тип регуляризации\n",
    "}\n",
    "\n",
    "# Настройка HyperbandSearchCV\n",
    "search = HyperbandSearchCV(clf, param_dist, max_iter=10)\n",
    "\n",
    "# Обучение с использованием поиска гиперпараметров\n",
    "search.fit(X, y, classes=[0, 1])  # Передача всех возможных классов\n",
    "\n",
    "# Вывод лучших параметров\n",
    "print(\"Лучшие параметры:\", search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3099e7cb",
   "metadata": {},
   "source": [
    "Dask-ML предоставляет распределённый алгоритм K-Means, который может обрабатывать большие данные и поддерживает вычисления в памяти и на диске."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de2ffb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/dask/base.py:1103: UserWarning: Running on a single-machine scheduler when a distributed client is active might lead to unexpected results.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кластеры: [0 2 2 ... 1 0 2]\n"
     ]
    }
   ],
   "source": [
    "from dask_ml.cluster import KMeans\n",
    "import dask.array as da\n",
    "\n",
    "# Создание синтетических данных\n",
    "X = da.random.random((100000, 10), chunks=(1000, 10))\n",
    "\n",
    "# Инициализация K-Means\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "\n",
    "# Обучение модели\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Получение кластеров\n",
    "print(\"Кластеры:\", kmeans.labels_.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869221ac",
   "metadata": {},
   "source": [
    "## Dask Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7776d44",
   "metadata": {},
   "source": [
    "Dask Scheduler — это распределённая система планирования задач, используемая Dask для управления вычислениями на одном компьютере или в распределённом кластере. Она определяет, какие задачи нужно выполнить, когда и где, обеспечивая эффективное распределение ресурсов и параллельное выполнение."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a023021",
   "metadata": {},
   "source": [
    "Dask поддерживает три основных типа планировщиков, которые подходят для разных случаев:\n",
    "\n",
    "1. Single-Threaded Scheduler\n",
    "\n",
    "2. Threaded Scheduler\n",
    "\n",
    "3. Distributed Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23c4134",
   "metadata": {},
   "source": [
    "**Когда использовать Distributed Scheduler?** Например, вы:\n",
    "\n",
    "обрабатываете очень большие данные, которые не помещаются в память одного компьютера\n",
    "\n",
    "хотите распределить вычисления между несколькими серверами или машинами\n",
    "\n",
    "нужно выполнить сложные задачи с большим количеством зависимостей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1aa7374",
   "metadata": {},
   "source": [
    "## Dask Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea21ca20",
   "metadata": {},
   "source": [
    "## Dask ETL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
