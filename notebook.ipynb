{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dask",
   "id": "4eaabe7791de8e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dask - это библиотека для параллельных вычислений и масштабирования. Допустим, что Numpy не справляется с объемом данных, который нам нужно будет обработать. В таком случае естественной альтернативой как раз станет Dask. Dask предоставляет возможность работать с данными, которые превышают объем оперативной памяти, и эффективно использовать ресурсы как на локальной машине, так и на кластере. Библиотека позволяет масштабировать код Python с минимальными изменениями.",
   "id": "3b0866b873e18ef1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Полезные ссылки",
   "id": "c0472af2d568ca8d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "[Тык](https://docs.dask.org/en/stable/)\n",
    "\n",
    "[Тык](https://tutorial.dask.org/00_overview.html)\n",
    "\n",
    "[Тык](https://habr.com/ru/companies/otus/articles/759552/)"
   ],
   "id": "29291f71cc75d8d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Установка",
   "id": "d38d1de40e22ccbd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Здесь все стандартно:",
   "id": "af1454e34d3ca316"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-10T09:18:47.576563Z",
     "start_time": "2024-12-10T09:18:46.714320Z"
    }
   },
   "source": "!pip install \"dask[complete]\"",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dask[complete] in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (2024.12.0)\r\n",
      "Requirement already satisfied: click>=8.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (8.1.7)\r\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (3.1.0)\r\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (2024.10.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (24.2)\r\n",
      "Requirement already satisfied: partd>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (1.4.2)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (6.0.2)\r\n",
      "Requirement already satisfied: toolz>=0.10.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (1.0.0)\r\n",
      "Requirement already satisfied: pyarrow>=14.0.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (18.1.0)\r\n",
      "Requirement already satisfied: lz4>=4.3.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (4.3.3)\r\n",
      "Requirement already satisfied: locket in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from partd>=1.4.0->dask[complete]) (1.0.0)\r\n",
      "Requirement already satisfied: numpy>=1.24 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (2.1.2)\r\n",
      "Requirement already satisfied: pandas>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (2.2.3)\r\n",
      "Requirement already satisfied: dask-expr<1.2,>=1.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (1.1.20)\r\n",
      "Requirement already satisfied: distributed==2024.12.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (2024.12.0)\r\n",
      "Requirement already satisfied: bokeh>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (3.6.2)\r\n",
      "Requirement already satisfied: jinja2>=2.10.3 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from dask[complete]) (3.1.4)\r\n",
      "Requirement already satisfied: msgpack>=1.0.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from distributed==2024.12.0->dask[complete]) (1.1.0)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in /Users/albertzhemukov/Library/Python/3.13/lib/python/site-packages (from distributed==2024.12.0->dask[complete]) (6.1.0)\r\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from distributed==2024.12.0->dask[complete]) (2.4.0)\r\n",
      "Requirement already satisfied: tblib>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from distributed==2024.12.0->dask[complete]) (3.0.0)\r\n",
      "Requirement already satisfied: tornado>=6.2.0 in /Users/albertzhemukov/Library/Python/3.13/lib/python/site-packages (from distributed==2024.12.0->dask[complete]) (6.4.2)\r\n",
      "Requirement already satisfied: urllib3>=1.26.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from distributed==2024.12.0->dask[complete]) (2.2.3)\r\n",
      "Requirement already satisfied: zict>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from distributed==2024.12.0->dask[complete]) (3.0.0)\r\n",
      "Requirement already satisfied: contourpy>=1.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from bokeh>=3.1.0->dask[complete]) (1.3.0)\r\n",
      "Requirement already satisfied: pillow>=7.1.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from bokeh>=3.1.0->dask[complete]) (11.0.0)\r\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from bokeh>=3.1.0->dask[complete]) (2024.9.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from jinja2>=2.10.3->dask[complete]) (3.0.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas>=2.0->dask[complete]) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas>=2.0->dask[complete]) (2024.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from pandas>=2.0->dask[complete]) (2024.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas>=2.0->dask[complete]) (1.16.0)\r\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dask Array",
   "id": "8889c3db692cd4c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dask Array — это масштабируемая версия массива NumPy, которая работает с массивами, превышающими объем оперативной памяти, и распределяет вычисления между несколькими ядрами или машинами.",
   "id": "9b487daee63ae4be"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Dask Array поддерживает API NumPy, что позволяет использовать знакомые функции и методы.\n",
    "\n",
    "- Массивы разбиваются на более мелкие блоки, которые обрабатываются независимо.\n",
    "\n",
    "- Поддерживаются вычисления как на локальной машине, так и в распределенных системах."
   ],
   "id": "2550f73cc6ab3f8a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Рассмотрим для начала пример из документации:",
   "id": "207fa0ba0343c15a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "43640558f269a226"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T09:20:15.047610Z",
     "start_time": "2024-12-10T09:18:56.796302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import dask.array as da\n",
    "\n",
    "# Создаем обычный NumPy массив размером 10x10\n",
    "x = np.arange(100).reshape(10, 10)\n",
    "# Преобразуем NumPy массив в Dask Array с чанками (разбиением) 5x5\n",
    "dask_array = da.from_array(x, chunks=(5, 5))\n",
    "\n",
    "result = dask_array.mean()\n",
    "print(result.compute())"
   ],
   "id": "c9c302565998fe2",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m dask_array \u001B[38;5;241m=\u001B[39m da\u001B[38;5;241m.\u001B[39mfrom_array(x, chunks\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m5\u001B[39m))\n\u001B[1;32m      9\u001B[0m result \u001B[38;5;241m=\u001B[39m dask_array\u001B[38;5;241m.\u001B[39mmean()\n\u001B[0;32m---> 10\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/dask/base.py:372\u001B[0m, in \u001B[0;36mDaskMethodsMixin.compute\u001B[0;34m(self, **kwargs)\u001B[0m\n\u001B[1;32m    348\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    349\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute this dask collection\u001B[39;00m\n\u001B[1;32m    350\u001B[0m \n\u001B[1;32m    351\u001B[0m \u001B[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    370\u001B[0m \u001B[38;5;124;03m    dask.compute\u001B[39;00m\n\u001B[1;32m    371\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 372\u001B[0m     (result,) \u001B[38;5;241m=\u001B[39m \u001B[43mcompute\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtraverse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    373\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/dask/base.py:660\u001B[0m, in \u001B[0;36mcompute\u001B[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001B[0m\n\u001B[1;32m    657\u001B[0m     postcomputes\u001B[38;5;241m.\u001B[39mappend(x\u001B[38;5;241m.\u001B[39m__dask_postcompute__())\n\u001B[1;32m    659\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m shorten_traceback():\n\u001B[0;32m--> 660\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[43mschedule\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdsk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    662\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m repack([f(r, \u001B[38;5;241m*\u001B[39ma) \u001B[38;5;28;01mfor\u001B[39;00m r, (f, a) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(results, postcomputes)])\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py:659\u001B[0m, in \u001B[0;36mEvent.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    657\u001B[0m signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flag\n\u001B[1;32m    658\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m signaled:\n\u001B[0;32m--> 659\u001B[0m     signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cond\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    660\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m signaled\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/threading.py:363\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    361\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    362\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 363\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    364\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    365\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m waiter\u001B[38;5;241m.\u001B[39macquire(\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Разберемся, что здесь вообще происходит.\n",
    "\n",
    "Вместо того чтобы обрабатывать весь массив сразу, Dask делит его на чанки, что позволяет работать с большими данными, превышающими оперативную память.\n",
    "Выполнение вычислений параллелизуется, что ускоряет процесс на многопроцессорных системах."
   ],
   "id": "5d4f71c7f6acb2ef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![dask-array](images/dask-array-2.png)",
   "id": "f5e711b16ca80a79"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "На изображении показано, как Dask Array разбивает большой массив на более мелкие части — чанки. Каждый чанк представляет собой отдельный NumPy массив.",
   "id": "359d8272913d6ddb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Пусть нам нужно вычислить индекс растительности NDVI для спутниковых данных, представляющих 10 сцен, каждая из которых состоит из двух каналов: ближний инфракрасный (NIR) и красный (Red). NDVI является важным показателем для анализа растительности, так как он показывает степень активности фотосинтеза в растительных покровах.",
   "id": "423a12fa05a482a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Генерируем массив данных: снимки 10000x10000 (10 сцен, 2 канала: NIR и Red)\n",
    "satellite_data = da.random.random((10, 2, 10_000, 10_000), chunks=(1, 2, 5000, 5000))\n",
    "\n",
    "# Разделяем каналы\n",
    "nir = satellite_data[:, 0, :, :]  # Near Infrared\n",
    "red = satellite_data[:, 1, :, :]  # Red\n",
    "\n",
    "# Вычисляем NDVI\n",
    "ndvi = (nir - red) / (nir + red)\n",
    "\n",
    "print(\"NDVI сцены 1, пиксель [0, 0]:\", ndvi[0, 0, 0].compute())"
   ],
   "id": "512dad63391bb196",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Попробуем сделать то же самое с NumPy (этот код ниже лучше не запускать - у меня, например, все 16 гигов оперативки кончились моментально)",
   "id": "ec1b8f50183b37"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Генерируем аналогичный массив данных: снимки 10000x10000 (10 сцен, 2 канала)\n",
    "\n",
    "# numpy_satellite_data = np.random.random((10, 2, 10_000, 10_000))\n",
    "\n",
    "# Разделяем каналы\n",
    "# nir = numpy_satellite_data[:, 0, :, :]  # Near Infrared\n",
    "# red = numpy_satellite_data[:, 1, :, :]  # Red\n",
    "\n",
    "# Вычисляем NDVI\n",
    "# try:\n",
    "    # ndvi = (nir - red) / (nir + red)\n",
    "    # print(\"NDVI сцены 1, пиксель [0, 0]:\", ndvi[0, 0, 0])\n",
    "# except MemoryError:\n",
    "    # print(\"NumPy не справился: данные слишком велики для оперативной памяти.\")"
   ],
   "id": "e8cc5a90c4993bec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Таким образом, мы посмотрели как работают массивы в Dask. Теперь потыкаем Bag",
   "id": "874d3988ce4eef82"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import dask.bag as db\n",
    "import random\n",
    "import string\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client()\n",
    "print(client.dashboard_link)\n",
    "\n",
    "# Функция для генерации случайной строки с набором слов\n",
    "def random_text(num_words=50):\n",
    "    words = [''.join(random.choices(string.ascii_lowercase, k=random.randint(3, 10))) for _ in range(num_words)]\n",
    "    return ' '.join(words)\n",
    "\n",
    "def process_line(line):\n",
    "    words = line.split()\n",
    "    return [word.lower() for word in words if word.isalpha()]\n",
    "\n",
    "num_lines = 50_000\n",
    "chunk_size = 10_000\n",
    "data = db.from_sequence((random_text() for _ in range(num_lines)), npartitions=num_lines // chunk_size)\n",
    "\n",
    "processed_data = data.map(process_line).flatten()  # Обрабатываем строки и объединяем их в один поток\n",
    "\n",
    "# Подсчитываем частоту каждого слова\n",
    "word_counts = processed_data.frequencies()\n",
    "\n",
    "# Получаем топ-10 самых частых слов\n",
    "top_10_words = word_counts.topk(10, key=lambda x: x[1])\n",
    "print(\"Топ-10 самых частых слов:\", top_10_words.compute())"
   ],
   "id": "5ab1814452ad15f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Как проверить прогресс выполнения",
   "id": "77afd6ea6532be6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dask поддерживает визуализацию выполнения задач через инструмент Dask Dashboard. Вы можете запустить его, добавив следующие строки:",
   "id": "effe7b2abd2de956"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "print(client.dashboard_link)  # Откроет ссылку на дашборд"
   ],
   "id": "a557bdc9facf8061",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "После запуска вы сможете видеть статус выполнения задач в режиме реального времени.",
   "id": "d9163f0a0322ab02"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
