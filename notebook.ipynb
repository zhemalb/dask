{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c74e8b3",
   "metadata": {},
   "source": [
    "# Deep Python 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d85654",
   "metadata": {},
   "source": [
    "Автор: Жемуков Альберт Артурович\n",
    "\n",
    "Cтудент БПМИ 239"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725451a0",
   "metadata": {},
   "source": [
    "## Предисловие"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37488148",
   "metadata": {},
   "source": [
    "После самостоятельного изучения библиотеки, ее документации и гайдов по ней, я создал этот доклад. Вместо исключительного объяснения как работает каждый метод, я постарался показать это преимущественно на примерах (котрые постарался сделать достаточно интересными). То есть, доклад это своего рода выжимка != документация. Он создан именно с целью потыкать код и при этом понять, что происходит. Другими словами, фундаментальные объяснения, которые есть в документации здесь вряд ли будут. Доклад построен на практических примерах."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1de893a",
   "metadata": {},
   "source": [
    "With that out of the way, погнали дальше!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84124c9",
   "metadata": {},
   "source": [
    "![chillguy](images/justachillguy-v0-cnvsm1t7p82e1.png.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eaabe7791de8e2",
   "metadata": {},
   "source": [
    "## Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19970fa",
   "metadata": {},
   "source": [
    "![logo](images/images.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0866b873e18ef1",
   "metadata": {},
   "source": [
    "Dask - это библиотека для параллельных вычислений и масштабирования. Допустим, что Numpy не справляется с объемом данных, который нам нужно будет обработать. В таком случае естественной альтернативой как раз станет Dask. Dask предоставляет возможность работать с данными, которые превышают объем оперативной памяти, и эффективно использовать ресурсы как на локальной машине, так и на кластере. Библиотека позволяет масштабировать код Python с минимальными изменениями."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c84c9c4",
   "metadata": {},
   "source": [
    "## Немного теории"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eaa4cf",
   "metadata": {},
   "source": [
    "Кластер — это группа компьютеров, объединённых вместе для совместного выполнения задач. Они работают как единая система и часто используются для увеличения производительности, масштабируемости и надежности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fa06e5",
   "metadata": {},
   "source": [
    "Кластер работает благодаря взаимодействию нескольких компонентов. Контроллер (мастер-узел) отвечает за управление распределением задач между узлами, отслеживает их состояние и следит за использованием ресурсов, таких как память и процессоры. Рабочие узлы (worker-узлы) выполняют задачи, которые им передает контроллер, обрабатывают данные или производят вычисления. Все узлы в кластере связаны между собой через локальную или облачную сеть, что позволяет им обмениваться данными и координировать выполнение задач в реальном времени."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab964af1",
   "metadata": {},
   "source": [
    "Dask поддерживает работу на локальном компьютере, но его ключевая сила — распределенные вычисления на кластерах."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c368a1d",
   "metadata": {},
   "source": [
    "Кластеры — это основа современных вычислений, особенно в сфере анализа данных, машинного обучения и высокопроизводительных вычислений."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0472af2d568ca8d",
   "metadata": {},
   "source": [
    "## Полезные ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29291f71cc75d8d2",
   "metadata": {},
   "source": [
    "[Официальная документация либы](https://docs.dask.org/en/stable/)\n",
    "\n",
    "[Официальный туториал](https://tutorial.dask.org/00_overview.html)\n",
    "\n",
    "[Офигенная статья на Хабре](https://habr.com/ru/companies/otus/articles/759552/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38d1de40e22ccbd",
   "metadata": {},
   "source": [
    "## Установка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1454e34d3ca316",
   "metadata": {},
   "source": [
    "Здесь все стандартно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T09:18:47.576563Z",
     "start_time": "2024-12-10T09:18:46.714320Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%pip install \"dask[complete]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8889c3db692cd4c",
   "metadata": {},
   "source": [
    "## Dask Array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b487daee63ae4be",
   "metadata": {},
   "source": [
    "Dask Array — это масштабируемая версия массива NumPy, которая работает с массивами, превышающими объем оперативной памяти, и распределяет вычисления между несколькими ядрами или машинами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2550f73cc6ab3f8a",
   "metadata": {},
   "source": [
    "- Dask Array поддерживает API NumPy, что позволяет использовать знакомые функции и методы.\n",
    "\n",
    "- Массивы разбиваются на более мелкие блоки, которые обрабатываются независимо.\n",
    "\n",
    "- Поддерживаются вычисления как на локальной машине, так и в распределенных системах."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207fa0ba0343c15a",
   "metadata": {},
   "source": [
    "Рассмотрим для начала пример:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c302565998fe2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T09:20:15.047610Z",
     "start_time": "2024-12-10T09:18:56.796302Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dask.array as da\n",
    "\n",
    "# Создаем обычный NumPy массив размером 10x10\n",
    "x = np.arange(100).reshape(10, 10)\n",
    "# Преобразуем NumPy массив в Dask Array с чанками (разбиением) 5x5\n",
    "dask_array = da.from_array(x, chunks=(5, 5))\n",
    "\n",
    "result = dask_array.mean()\n",
    "print(result.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4f71c7f6acb2ef",
   "metadata": {},
   "source": [
    "Разберемся, что здесь вообще происходит.\n",
    "\n",
    "Вместо того чтобы обрабатывать весь массив сразу, Dask делит его на чанки, что позволяет работать с большими данными, превышающими оперативную память.\n",
    "Выполнение вычислений параллелизуется, что ускоряет процесс на многопроцессорных системах."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e711b16ca80a79",
   "metadata": {},
   "source": [
    "![dask-array](images/dask-array-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359d8272913d6ddb",
   "metadata": {},
   "source": [
    "На изображении показано, как Dask Array разбивает большой массив на более мелкие части — чанки. Каждый чанк представляет собой отдельный NumPy массив."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423a12fa05a482a5",
   "metadata": {},
   "source": [
    "Пусть нам нужно вычислить индекс растительности NDVI для спутниковых данных, представляющих 10 сцен, каждая из которых состоит из двух каналов: ближний инфракрасный (NIR) и красный (Red). NDVI является важным показателем для анализа растительности, так как он показывает степень активности фотосинтеза в растительных покровах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512dad63391bb196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерируем массив данных: снимки 10000x10000 (10 сцен, 2 канала: NIR и Red)\n",
    "satellite_data = da.random.random((10, 2, 10_000, 10_000), chunks=(1, 2, 5000, 5000))\n",
    "\n",
    "# Разделяем каналы\n",
    "nir = satellite_data[:, 0, :, :]  # Near Infrared\n",
    "red = satellite_data[:, 1, :, :]  # Red\n",
    "\n",
    "# Вычисляем NDVI\n",
    "ndvi = (nir - red) / (nir + red)\n",
    "\n",
    "print(\"NDVI сцены 1, пиксель [0, 0]:\", ndvi[0, 0, 0].compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1b8f50183b37",
   "metadata": {},
   "source": [
    "Попробуем сделать то же самое с NumPy (этот код ниже лучше не запускать)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cc5a90c4993bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерируем аналогичный массив данных: снимки 10000x10000 (10 сцен, 2 канала)\n",
    "\n",
    "# numpy_satellite_data = np.random.random((10, 2, 10_000, 10_000))\n",
    "\n",
    "# Разделяем каналы\n",
    "# nir = numpy_satellite_data[:, 0, :, :]  # Near Infrared\n",
    "# red = numpy_satellite_data[:, 1, :, :]  # Red\n",
    "\n",
    "# Вычисляем NDVI\n",
    "# try:\n",
    "    # ndvi = (nir - red) / (nir + red)\n",
    "    # print(\"NDVI сцены 1, пиксель [0, 0]:\", ndvi[0, 0, 0])\n",
    "# except MemoryError:\n",
    "    # print(\"NumPy не справился: данные слишком велики для оперативной памяти.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874d3988ce4eef82",
   "metadata": {},
   "source": [
    "Таким образом, мы посмотрели как работают массивы в Dask. Теперь потыкаем Bag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0958d805",
   "metadata": {},
   "source": [
    "## Dask Bag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded21455",
   "metadata": {},
   "source": [
    "Dask Bag — это компонент библиотеки Dask, предназначенный для параллельной обработки коллекций произвольных Python объектов с использованием операций, таких как map, filter, fold и groupby. Он эффективно работает с неструктурированными или полуструктурированными данными, такими как текстовые файлы, лог-файлы, JSON-записи или пользовательские объекты Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd25dd3",
   "metadata": {},
   "source": [
    "Рассмотрим задачу подсчета наиболее частых слов в наборе текстовых файлов (например, анализ лог-файлов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab1814452ad15f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "from datetime import datetime\n",
    "from dask.distributed import Client\n",
    "import dask.bag as db\n",
    "\n",
    "# Запуск Dask Dashboard\n",
    "client = Client()\n",
    "print(client.dashboard_link)\n",
    "\n",
    "# Функция для генерации случайной строки логов\n",
    "def generate_log_line():\n",
    "    ip = \".\".join(str(random.randint(0, 255)) for _ in range(4))  # Генерация случайного IP-адреса\n",
    "    timestamp = datetime.now().strftime('%d/%b/%Y:%H:%M:%S')  # Текущее время в формате логов\n",
    "    http_methods = [\"GET\", \"POST\", \"PUT\", \"DELETE\", \"PATCH\"]\n",
    "    method = random.choice(http_methods)  # Случайный HTTP-метод\n",
    "    url = \"/\" + \"/\".join(\n",
    "        ''.join(random.choices(string.ascii_lowercase, k=random.randint(3, 10))) for _ in range(3)\n",
    "    )  # Случайный URL\n",
    "    status = random.choice([200, 201, 400, 404, 500])  # Случайный статус ответа\n",
    "    response_time = random.uniform(0.1, 5.0)  # Время ответа в секундах\n",
    "\n",
    "    return f'{ip} - - [{timestamp}] \"{method} {url} HTTP/1.1\" {status} {int(response_time * 1000)}'\n",
    "\n",
    "# Обработка строк логов: выделение частей лога для анализа\n",
    "def process_log_line(line):\n",
    "    parts = line.split()\n",
    "    if len(parts) < 9:  # Проверка на валидность строки лога\n",
    "        return []\n",
    "    ip = parts[0]  # IP-адрес\n",
    "    method = parts[5].strip('\"')  # HTTP-метод\n",
    "    status = parts[8]  # Статус ответа\n",
    "    return [ip, method, status]\n",
    "\n",
    "# Генерация 1 миллиона строк логов с ленивым генератором\n",
    "num_lines = 1 * 10 ** 6\n",
    "chunk_size = 1 * 10 ** 5\n",
    "data = db.from_sequence((generate_log_line() for _ in range(num_lines)), npartitions=num_lines // chunk_size)\n",
    "\n",
    "# Обработка логов\n",
    "processed_data = data.map(process_log_line).flatten()  # Обрабатываем строки логов\n",
    "\n",
    "# Подсчитываем частоту каждого элемента\n",
    "element_counts = processed_data.frequencies()\n",
    "\n",
    "# Получаем топ-10 самых частых элементов\n",
    "top_10_elements = element_counts.topk(10, key=lambda x: x[1])\n",
    "print(\"Топ-10 самых частых элементов:\", top_10_elements.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1978f36e",
   "metadata": {},
   "source": [
    "Dask Bag напоминает параллельную версию библиотеки PyToolz или Python-эквивалент RDD из Apache Spark. Благодаря ленивой обработке и использованию итераторов, Dask Bag позволяет работать с данными, превышающими объем оперативной памяти, и эффективно задействовать ресурсы нескольких ядер или даже машин."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77afd6ea6532be6",
   "metadata": {},
   "source": [
    "## Прогресс выполнения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effe7b2abd2de956",
   "metadata": {},
   "source": [
    "Dask поддерживает визуализацию выполнения задач через инструмент Dask Dashboard. Вы можете запустить его, добавив следующие строки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a557bdc9facf8061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dask.distributed import Client\n",
    "# client = Client()\n",
    "print(client.dashboard_link)  # Откроет ссылку на дашборд"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9163f0a0322ab02",
   "metadata": {},
   "source": [
    "После запуска вы сможете видеть статус выполнения задач в режиме реального времени."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b810fb8",
   "metadata": {},
   "source": [
    "## Dask DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8973da45",
   "metadata": {},
   "source": [
    "Dask DataFrame — это инструмент для работы с большими табличными данными, который позволяет масштабировать вычисления на основе библиотеки pandas. Если данные слишком велики для обработки в памяти или вычисления занимают слишком много времени, Dask DataFrame предоставляет решение, которое позволяет эффективно использовать ресурсы компьютера или распределенного кластера."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea9e9a7",
   "metadata": {},
   "source": [
    "API Dask DataFrame почти полностью повторяет API pandas. Большинство методов pandas можно использовать с Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f03a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Создаем pandas DataFrame\n",
    "data = pd.DataFrame({'a': range(100), 'b': range(100, 200)})\n",
    "\n",
    "# Преобразуем pandas DataFrame в Dask DataFrame\n",
    "dask_df = dd.from_pandas(data, npartitions=4)\n",
    "print(dask_df.head())  # Вывод первых строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea304c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Создаем тестовые данные\n",
    "def create_mock_data(file_type, directory=\"data\", num_files=3):\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    for i in range(num_files):\n",
    "        data = pd.DataFrame({\n",
    "            \"col1\": range(10 * i, 10 * (i + 1)),\n",
    "            \"col2\": [f\"text_{j}\" for j in range(10)],\n",
    "        })\n",
    "        file_path = os.path.join(directory, f\"file_{i}.{file_type}\")\n",
    "        if file_type == \"csv\":\n",
    "            data.to_csv(file_path, index=False)\n",
    "        elif file_type == \"parquet\":\n",
    "            data.to_parquet(file_path, index=False)\n",
    "        elif file_type == \"json\":\n",
    "            data.to_json(file_path, orient=\"records\", lines=True)\n",
    "    print(f\"{num_files} {file_type.upper()} files created in '{directory}/'\")\n",
    "\n",
    "# Чтение mock-файлов с помощью Dask\n",
    "def read_mock_files(file_type, directory=\"data\"):\n",
    "    if file_type == \"csv\":\n",
    "        df = dd.read_csv(f\"{directory}/*.csv\")\n",
    "    elif file_type == \"parquet\":\n",
    "        df = dd.read_parquet(f\"{directory}/*.parquet\")\n",
    "    elif file_type == \"json\":\n",
    "        df = dd.read_json(f\"{directory}/*.json\")\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type\")\n",
    "    \n",
    "    print(\"Пример данных:\")\n",
    "    print(df.head())\n",
    "    print(\"-\"*40)\n",
    "\n",
    "# Создаем mock CSV, Parquet и JSON файлы\n",
    "create_mock_data(\"csv\")\n",
    "create_mock_data(\"parquet\")\n",
    "create_mock_data(\"json\")\n",
    "\n",
    "# Читаем файлы и выводим пример данных\n",
    "read_mock_files(\"csv\")\n",
    "read_mock_files(\"parquet\")\n",
    "read_mock_files(\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a36b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_json('data/*.json')\n",
    "\n",
    "print(df.head()) # Первые строки\n",
    "print(df.info()) # Информация о DataFrame\n",
    "print(df.describe()) # Статистика"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9e8996",
   "metadata": {},
   "source": [
    "Если данные часто используются, их можно сохранить в оперативной памяти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db454ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "persisted_df = df.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468c63ff",
   "metadata": {},
   "source": [
    "Dask поддерживает запись данных в различные форматы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22d8a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запись в CSV\n",
    "df.to_csv('output/*.csv', index=False)\n",
    "\n",
    "# Запись в Parquet\n",
    "df.to_parquet('output/', engine='pyarrow') # директория output в репозитории должна обновиться"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33201693",
   "metadata": {},
   "source": [
    "## Dask Delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b859261f",
   "metadata": {},
   "source": [
    "Dask Delayed — это инструмент для параллельного выполнения пользовательских алгоритмов, которые не вписываются в стандартные высокоуровневые коллекции Dask, такие как Array, DataFrame или Bag. С помощью Dask Delayed можно создавать графы задач (task graphs), описывающие порядок выполнения функций, и выполнять их параллельно. Этот подход особенно полезен для вычислений, где присутствует явный параллелизм, но нет структуры данных, подходящей для стандартных коллекций Dask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81cbdc3",
   "metadata": {},
   "source": [
    "Вместо немедленного выполнения функции, Dask Delayed откладывает её выполнение и строит граф задач. Граф содержит функции, их аргументы и зависимости между ними. После построения графа задачи могут быть выполнены параллельно с использованием планировщиков Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4bb08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import delayed\n",
    "\n",
    "def inc(x):\n",
    "    return x + 1\n",
    "\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "x = delayed(inc)(1) # отложим выполнение на 1\n",
    "y = delayed(inc)(2) # отложим выполнение  на 2\n",
    "z = delayed(add)(x, y) # объект Delayed, содержащий граф задач\n",
    "print(z.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4d863f",
   "metadata": {},
   "source": [
    "Для упрощения кода dask.delayed часто также используется как декоратор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89bfa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@delayed\n",
    "def triple(x):\n",
    "    return x * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1e5ce0",
   "metadata": {},
   "source": [
    "Если задача зависит от побочного эффекта другой задачи, используется dask.graph_manipulation.bind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f5fd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.graph_manipulation import bind\n",
    "\n",
    "DATA = []\n",
    "\n",
    "@delayed\n",
    "def add_data(x):\n",
    "    DATA.append(x)\n",
    "\n",
    "@delayed\n",
    "def sum_data(x):\n",
    "    return sum(DATA) + x\n",
    "\n",
    "a = add_data(1)\n",
    "b = add_data(2)\n",
    "c = bind(sum_data, [a, b])(3)\n",
    "print(c.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b336297",
   "metadata": {},
   "source": [
    "Рассмотрим сценарий, где необходимо выполнить сложную цепочку вычислений над несколькими наборами данных, включающую загрузку данных из нескольких источников, их предварительную обработку, выполнение вычислений и сохранение результатов. Еще добавим зависимости, которые требуют выполнения задач в определенном порядке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db21d766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Имитация загрузки данных\n",
    "@delayed\n",
    "def load_data(source):\n",
    "    time.sleep(random.uniform(0.5, 1.5))  # Имитация задержки\n",
    "    print(f\"Загружаем данные из {source}\")\n",
    "    return [random.randint(1, 100) for _ in range(10)]  # Генерация данных\n",
    "\n",
    "# Обработка данных: фильтрация\n",
    "@delayed\n",
    "def filter_data(data, threshold):\n",
    "    print(f\"Фильтруем данные с порогом {threshold}\")\n",
    "    return [x for x in data if x > threshold]\n",
    "\n",
    "# Сложные вычисления: увеличение, затем умножение\n",
    "@delayed\n",
    "def computation(data):\n",
    "    print(\"Выполняем вычисления\")\n",
    "    time.sleep(1)  # Имитация тяжелых вычислений\n",
    "    return [x * 2 + 1 for x in data]\n",
    "\n",
    "# Финальная агрегация\n",
    "@delayed\n",
    "def aggregate(data1, data2):\n",
    "    print(\"Агрегация данных\")\n",
    "    return sum(data1) + sum(data2)\n",
    "\n",
    "# Сохранение результата\n",
    "@delayed\n",
    "def save_result(result, filename):\n",
    "    print(f\"Сохраняем результат в {filename}\")\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(str(result))\n",
    "    return f\"Результат сохранен в {filename}\"\n",
    "\n",
    "# Создание графа задач\n",
    "sources = [\"source_1\", \"source_2\"]\n",
    "\n",
    "# Загрузка данных\n",
    "data_1 = load_data(sources[0])\n",
    "data_2 = load_data(sources[1])\n",
    "\n",
    "# Обработка данных\n",
    "filtered_data_1 = filter_data(data_1, threshold=50)\n",
    "filtered_data_2 = filter_data(data_2, threshold=50)\n",
    "\n",
    "# Сложные вычисления\n",
    "computed_data_1 = computation(filtered_data_1)\n",
    "computed_data_2 = computation(filtered_data_2)\n",
    "\n",
    "# Агрегация данных\n",
    "final_result = aggregate(computed_data_1, computed_data_2)\n",
    "\n",
    "# Сохранение результатов\n",
    "save_task = save_result(final_result, \"examples/result.txt\")\n",
    "\n",
    "# Выполнение графа задач\n",
    "save_task.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da41ec2c",
   "metadata": {},
   "source": [
    "Добавим визуализацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a56c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install graphviz\n",
    "# brew install graphviz\n",
    "save_task.visualize(rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe71b906",
   "metadata": {},
   "source": [
    "По умолчанию Dask Delayed использует многопоточный планировщик (threaded scheduler) для минимизации затрат на передачу данных. Однако, если ваш код сильно зависит от GIL, например, при выполнении вычислений, доминирующих в чистом Python, или при использовании внешнего кода, который удерживает GIL, рекомендуется использовать другие планировщики."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e91385a",
   "metadata": {},
   "source": [
    "## Dask Futures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30a1d93",
   "metadata": {},
   "source": [
    "Dask Futures — это интерфейс для управления и выполнения задач в реальном времени, который позволяет легко масштабировать Python-код на кластере."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa59aa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "def square(x):\n",
    "    return x ** 2\n",
    "\n",
    "future = client.submit(square, 10)  # отправляем задачу\n",
    "print(future.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac9ef34",
   "metadata": {},
   "source": [
    "Dask Futures позволяет создавать задачи в реальном времени, даже в процессе выполнения других задач. Это может быть полезно, если объем работы неизвестен заранее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fc8631",
   "metadata": {},
   "outputs": [],
   "source": [
    "futures = [client.submit(square, i) for i in range(10)]\n",
    "results = client.gather(futures)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81339a23",
   "metadata": {},
   "source": [
    "Dask Futures позволяет задавать зависимости между задачами вручную, обеспечивая выполнение задач в правильном порядке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b5a814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "a = client.submit(square, 2)\n",
    "b = client.submit(square, 3)\n",
    "c = client.submit(add, a, b)\n",
    "print(c.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cd837a",
   "metadata": {},
   "source": [
    "Можно использовать методы map и gather для более эффективного управления несколькими задачами:\n",
    "\n",
    "1. clientmap применяет функцию к набору аргументов\n",
    "2. client.gather собирает результаты задач"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeb8948",
   "metadata": {},
   "outputs": [],
   "source": [
    "futures = client.map(square, range(10))\n",
    "results = client.gather(futures)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f4f072",
   "metadata": {},
   "source": [
    "Futures можно использовать совместно с коллекциями Dask, чтобы смешивать статические и динамические вычисления."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66397490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "# тение данных с помощью Dask DataFrame\n",
    "ddf = dd.read_csv(\"data/*.csv\")\n",
    "print(\"Предварительный просмотр данных:\")\n",
    "print(ddf.head())\n",
    "\n",
    "filtered_ddf = ddf[ddf[\"col1\"] % 2 == 0]  # Фильтруем четные значения\n",
    "\n",
    "# Динамические вычисления с Dask Futures\n",
    "def compute_metric(partition):\n",
    "    # Вычисляем сумму значений в партии\n",
    "    return partition[\"col1\"].sum()\n",
    "\n",
    "# Преобразуем каждую партицию в Future с использованием клиента\n",
    "delayed_partitions = filtered_ddf.to_delayed()\n",
    "futures = [client.submit(compute_metric, part.compute()) for part in delayed_partitions]\n",
    "\n",
    "# Собираем результаты из Futures\n",
    "results = client.gather(futures)\n",
    "\n",
    "# Итоговая сумма значений\n",
    "total_sum = sum(results)\n",
    "print(f\"Сумма значений после фильтрации: {total_sum}\")\n",
    "\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e51855",
   "metadata": {},
   "source": [
    "## Dask ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81281cca",
   "metadata": {},
   "source": [
    "Dask предоставляет инструменты для масштабирования задач машинного обучения, позволяя работать с большими данными, распределять вычисления и эффективно использовать ресурсы кластера. Dask интегрируется с популярными библиотеками, такими как Scikit-learn, XGBoost, LightGBM, и поддерживает динамическое управление задачами с помощью интерфейса Futures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4cc3a5",
   "metadata": {},
   "source": [
    "Dask интегрируется с Optuna для распределенной оптимизации гиперпараметров. Это позволяет запускать большое количество экспериментов параллельно, синхронизируя результаты через планировщик Dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0fdc41cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/distributed/node.py:187: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 64889 instead\n",
      "  warnings.warn(\n",
      "[I 2024-12-10 19:30:25,555] A new study created in memory with name: no-name-3fa93cf1-a7ad-420f-b867-cc612a651238\n",
      "[I 2024-12-10 19:30:26,551] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 12, 'max_depth': 9, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-12-10 19:30:26,576] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 29, 'max_depth': 7, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-12-10 19:30:26,583] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 25, 'max_depth': 4, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-12-10 19:30:26,596] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 64, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 7}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-12-10 19:30:26,602] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 66, 'max_depth': 2, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-12-10 19:30:26,607] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 55, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 7}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-12-10 19:30:26,621] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 61, 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-12-10 19:30:26,634] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 52, 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 9}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-12-10 19:30:26,639] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 78, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-12-10 19:30:26,644] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 61, 'max_depth': 4, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-12-10 19:30:26,645] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 29, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 6}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-12-10 19:30:26,647] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 91, 'max_depth': 6, 'min_samples_split': 8, 'min_samples_leaf': 9}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-12-10 19:30:26,664] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 48, 'max_depth': 4, 'min_samples_split': 3, 'min_samples_leaf': 8}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-12-10 19:30:26,664] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 65, 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 6}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-12-10 19:30:26,671] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 61, 'max_depth': 9, 'min_samples_split': 2, 'min_samples_leaf': 6}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-12-10 19:30:26,681] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 58, 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 2}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-12-10 19:30:26,691] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 64, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-12-10 19:30:26,699] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 97, 'max_depth': 2, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-12-10 19:30:26,700] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 57, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 0 with value: 1.0.\n",
      "[I 2024-12-10 19:30:26,707] Trial 0 finished with value: 1.0 and parameters: {'n_estimators': 62, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 0 with value: 1.0.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No trials are completed yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 60\u001b[0m\n\u001b[1;32m     57\u001b[0m study \u001b[38;5;241m=\u001b[39m optimize_with_futures()\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Вывод лучших параметров\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mЛучшие параметры:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_params\u001b[49m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Завершаем работу клиента\u001b[39;00m\n\u001b[1;32m     63\u001b[0m client\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/optuna/study/study.py:119\u001b[0m, in \u001b[0;36mStudy.best_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbest_params\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m    109\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return parameters of the best trial in the study.\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \n\u001b[1;32m    111\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m \n\u001b[1;32m    117\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_trial\u001b[49m\u001b[38;5;241m.\u001b[39mparams\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/optuna/study/study.py:162\u001b[0m, in \u001b[0;36mStudy.best_trial\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_multi_objective():\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA single best trial cannot be retrieved from a multi-objective study. Consider \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing Study.best_trials to retrieve a list containing the best trials.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m     )\n\u001b[0;32m--> 162\u001b[0m best_trial \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_storage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_best_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_study_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;66;03m# If the trial with the best value is infeasible, select the best trial from all feasible\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# trials. Note that the behavior is undefined when constrained optimization without the\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# violation value in the best-valued trial.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m constraints \u001b[38;5;241m=\u001b[39m best_trial\u001b[38;5;241m.\u001b[39msystem_attrs\u001b[38;5;241m.\u001b[39mget(_CONSTRAINTS_KEY)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/optuna/storages/_in_memory.py:249\u001b[0m, in \u001b[0;36mInMemoryStorage.get_best_trial\u001b[0;34m(self, study_id)\u001b[0m\n\u001b[1;32m    246\u001b[0m best_trial_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_studies[study_id]\u001b[38;5;241m.\u001b[39mbest_trial_id\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_trial_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo trials are completed yet.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_studies[study_id]\u001b[38;5;241m.\u001b[39mdirections) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial can be obtained only for single-objective optimization.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: No trials are completed yet."
     ]
    }
   ],
   "source": [
    "# Установка необходимых библиотек\n",
    "# %pip install optuna dask[complete] scikit-learn\n",
    "\n",
    "import optuna\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from dask.distributed import LocalCluster, Client, wait\n",
    "\n",
    "# Настройка Dask-кластера\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "\n",
    "# Загрузка данных\n",
    "data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.data, data.target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Определение функции обучения модели\n",
    "def train_model(train_data, **params):\n",
    "    X_train, y_train = train_data\n",
    "    model = RandomForestClassifier(**params, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Определение функции оценки модели\n",
    "def evaluate_model(model, test_data):\n",
    "    X_test, y_test = test_data\n",
    "    y_pred = model.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Определение функции цели для Optuna\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 100),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "    }\n",
    "    model = train_model((X_train, y_train), **params)\n",
    "    score = evaluate_model(model, (X_test, y_test))\n",
    "    return score\n",
    "\n",
    "# Функция для распределенной оптимизации гиперпараметров\n",
    "def optimize_with_futures():\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "    # Запуск нескольких задач параллельно через Dask\n",
    "    futures = [client.submit(study.optimize, objective, n_trials=1, pure=False) for _ in range(20)]\n",
    "    wait(futures)  # Ожидание завершения всех задач\n",
    "\n",
    "    return study\n",
    "\n",
    "# Запуск оптимизации\n",
    "study = optimize_with_futures()\n",
    "\n",
    "# Вывод лучших параметров\n",
    "print(\"Лучшие параметры:\", study.best_params)\n",
    "\n",
    "# Завершаем работу клиента\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869221ac",
   "metadata": {},
   "source": [
    "## Dask Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1aa7374",
   "metadata": {},
   "source": [
    "## Dask Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea21ca20",
   "metadata": {},
   "source": [
    "## Dask ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af27335",
   "metadata": {},
   "source": [
    "## На этом все!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
